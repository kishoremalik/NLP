{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_Torch_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "uaWA9-sj3Rpr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# url: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wBPhzi7T4DdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZgC3tMeP4WgR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# dataset"
      ]
    },
    {
      "metadata": {
        "id": "v6Bh0Z3H4Yf9",
        "colab_type": "code",
        "outputId": "e613584e-ef90-4114-e48f-ecdbc0a087f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 10.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "l2yPR1k255sN",
        "colab_type": "code",
        "outputId": "51b8a513-ec06-40fc-9bec-43595aa8eaac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "umA5-P0y6NkD",
        "colab_type": "code",
        "outputId": "75d67d9c-4585-4aed-efbd-74705826dfb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['If', 'you', 'were', 'a', 'director', 'that', 'was', 'looking', 'to', 'cast', 'female', 'victims', 'for', 'a', 'slasher', 'movie', ',', 'then', 'surely', 'it', 'would', 'make', 'sense', 'to', 'add', 'a', 'couple', 'of', 'porn', 'stars', '?', 'It', \"'s\", 'not', 'as', 'if', 'they', \"'re\", 'inexperienced', 'in', 'front', 'of', 'the', 'camera', ',', 'they', 'have', 'no', 'qualms', 'with', 'the', 'requisite', 'nudity', 'and', 'how', 'many', 'unattractive', 'porn', 'queens', 'can', 'you', 'name', '?', 'Christian', 'Viel', 'obviously', 'recognized', 'the', 'potential', 'of', 'mixing', 'hardcore', 'actresses', 'with', 'hard', '-', 'gore', 'effects', 'and', 'so', 'he', 'cast', 'four', 'of', 'adult', 'cinema', \"'s\", 'sexiest', 'and', 'most', 'notorious', 'stars', '.', 'Jenna', 'Jameson', ',', 'Chasey', 'Lain', ',', 'Ginger', 'Lynn', 'Allen', 'and', 'Taylor', 'Hayes', 'all', 'turn', 'up', 'for', 'cameos', 'in', 'arguably', 'the', 'most', 'intriguing', 'slasher', 'flick', 'to', 'be', 'released', 'since', 'Scream', 'Reinvigorated', 'the', 'genre.<br', '/><br', '/>Samhain', 'was', 'originally', 'intended', 'for', 'a', 'cinema', 'release', 'in', 'October', '2002', '-', 'thus', 'keeping', 'in', 'check', 'with', 'the', 'Halloween', '-', 'based', 'synopsis', '.', 'Unfortunately', ',', 'the', 'shoot', 'was', 'plagued', 'by', 'numerous', 'problems', ',', 'which', 'have', 'thus', 'prevented', 'the', 'feature', 'from', 'achieving', 'the', 'exposure', 'that', 'it', 'deserves', '.', 'Last', 'I', 'heard', 'it', 'had', 'been', 'signed', 'by', 'Film', '2000', 'here', 'in', 'the', 'UK', 'and', 'was', 'penned', 'for', 'a', 'late', 'October', 'release', 'direct', 'to', 'DVD', '.', 'Unfortunately', 'that', 'label', 'has', 'got', 'a', 'peerlessly', 'abysmal', 'track', 'record', 'with', 'DTV', 'slashers', '.', 'Not', 'content', 'with', 'polluting', 'our', 'shelves', 'with', 'Camp', 'Blood', 'and', 'its', 'follow', 'up', ',', 'they', 'were', 'also', 'responsible', 'for', 'unleashing', 'Granny', ',', 'Bleed', 'and', 'the', 'rancid', 'Paranoid', '.', 'Could', 'Samhain', 'finally', 'be', 'worthwhile', 'ammunition', 'to', 'their', 'contemptible', 'catalogue', 'cannon', '?', '<', 'br', '/><br', '/>Five', 'Canadian', '/', 'American', 'students', 'and', 'their', 'teacher', 'head', 'to', 'Southern', 'Ireland', 'as', 'part', 'of', 'their', 'history', 'course', '.', 'Upon', 'arrival', 'they', 'are', 'told', 'the', 'legend', 'of', 'a', 'cannibalistic', 'clan', 'that', 'roamed', 'the', 'hills', 'of', 'Scotland', 'and', 'murdered', 'locals', 'for', 'food', '.', 'The', 'cannibals', 'were', 'eventually', 'caught', 'and', 'burnt', 'at', 'the', 'stake', ',', 'but', 'it', \"'s\", 'rumored', 'that', 'one', 'of', 'the', 'tribe', 'escaped', 'and', 'headed', 'to', 'the', 'woodland', 'of', 'Ireland', 'to', 'find', 'refuge', '.', 'After', 'the', 'kids', 'have', 'settled', 'and', 'begun', 'doing', 'what', 'all', 'massacre', '-', 'fodder', 'does', 'in', 'these', 'flicks', ',', 'the', 'mandatory', 'goody', 'two', '-', 'shoes', '(', 'and', 'definite', 'heroine', 'candidate', ')', 'begins', 'to', 'be', 'spooked', 'by', 'a', 'shadow', 'creeping', 'around', 'late', 'at', 'night', '.', 'Could', 'it', 'be', 'that', 'the', 'flesh', 'hungry', 'maniac', 'is', 'still', 'at', 'large', 'in', 'the', 'Forest', '?', 'Well', 'what', 'do', 'you', 'think', '\\x85', '?', '<', 'br', '/><br', '/>It', 'looks', 'as', 'if', 'Samhain', \"'s\", 'production', 'was', 'jinxed', 'right', 'from', 'the', 'start', '.', 'Almost', 'immediately', 'Wallmart', 'refused', 'to', 'develop', 'Jenna', 'Jameson', \"'s\", 'nude', 'make', '-', 'up', 'shots', ',', 'and', 'Chasey', 'Lain', 'began', 'acting', 'characteristically', 'like', 'a', 'drugged', '-', 'out', 'primadonna', '.', 'Finally', 'to', 'add', 'insult', 'to', 'injury', ',', 'the', 'producers', 'got', 'cold', 'feet', 'just', 'before', 'the', 'flick', 'was', 'about', 'to', 'hit', 'shelves', 'and', 'began', 'talking', 'of', 're', '-', 'editing', 'and', 'removing', 'all', 'the', 'gore', '.', 'Reports', 'have', 'said', 'that', 'they', 'were', 'unhappy', 'about', 'the', 'copious', 'amounts', 'of', 'violence', 'and', 'they', 'wanted', 'to', 'trim', 'scenes', 'down', 'so', 'it', 'would', 'achieve', 'an', 'R', 'rating', '.', 'Veil', 'of', 'course', 'disagreed', ',', 'seeing', 'how', 'his', 'entire', 'synopsis', 'was', 'boosted', 'by', 'its', 'creatively', 'graphic', 'display', '.', 'Eventually', 'after', 'months', 'of', 'arguments', ',', 'the', 'director', 'parted', 'company', 'with', 'Warehouse', 'productions', 'and', 'the', 'feature', 'was', 'once', 'again', 'locked', 'in', 'the', 'vaults.<br', '/><br', '/>Despite', 'countless', 'disruptions', ',', 'Veil', \"'s\", 'slasher', 'opus', 'is', 'still', 'one', 'of', 'the', 'best', 'genre', 'pieces', 'to', 'be', 'released', 'since', 'the', 'new', 'millennium', '.', 'The', 'copy', 'I', 'was', 'sent', 'was', 'the', 'pre', '-', 'release', 'screener', ',', 'which', 'was', 'obviously', 'a', 'test', 'press', 'without', 'sound', 'effects', 'or', 'the', 'complete', 'soundtrack', '.', 'But', 'still', 'it', 'boasted', 'a', 'few', 'credible', 'jump', '-', 'scares', ',', 'some', 'superb', 'cinematography', 'and', 'a', 'couple', 'of', 'the', 'goriest', 'set', 'pieces', 'that', 'I', \"'ve\", 'seen', 'for', 'some', 'time', '.', 'One', 'guy', 'is', 'disemboweled', 'via', 'his', 'rectum', 'before', 'being', 'strangled', 'with', 'his', 'own', 'intestine', ',', 'Jenna', 'Jameson', 'is', 'stripped', 'naked', 'and', 'gutted', 'in', 'unflinching', 'close', 'up', 'and', 'Chasey', 'Lain', 'ends', 'up', \"'\", 'spilling', 'her', 'guts', \"'\", 'after', 'an', 'unfortunate', 'rescue', 'attempt', 'from', 'her', 'boyfriend', '(', 'Richard', 'Grieco', ')', '.', 'Even', 'though', 'the', 'murders', 'are', 'uncommonly', 'gruesome', ',', 'Samhain', 'never', 'feels', 'mean', 'spirited', ',', 'which', 'is', 'basically', 'due', 'to', 'the', 'characters', 'being', 'thinly', 'portrayed', 'as', 'basic', 'slasher', 'clichés', '.', 'In', 'all', 'honesty', 'the', 'script', 'was', 'perhaps', 'the', 'movies', 'biggest', 'downfall', ',', 'because', 'the', 'dialogue', 'was', 'not', 'so', 'much', 'inspired', 'by', 'Wes', 'Craven', \"'s\", 'Scream', 'movies', 'as', 'it', 'was', 'flagrantly', 'cut', 'and', 'pasted', 'from', 'them.<br', '/><br', '/>Certainly', 'the', 'inclusion', 'of', 'the', 'mouth', '-', 'watering', 'Jenna', 'Jameson', 'was', 'a', 'great', 'move', 'by', 'the', 'producers', '.', 'Her', 'fans', 'will', 'be', 'excited', 'to', 'know', 'that', 'she', 'does', 'whip', 'off', 'her', 'top', '(', 'as', 'expected', ')', 'and', 'so', 'does', 'Chasey', 'Lain', 'and', 'Taylor', 'Hayes', '.', 'But', 'Samhain', 'is', 'no', 'soft', 'porn', 'movie', ',', 'and', 'it', 'benefits', 'from', 'sticking', 'to', 'the', 'structure', 'that', 'it', 'set', 'out', 'to', 'produce', '.', 'It', \"'s\", 'worth', 'noting', 'that', 'the', 'aforementioned', 'XXX', 'stars', 'almost', 'out', '-', 'perform', 'the', 'supposed', \"'\", 'actors', \"'\", 'of', 'the', 'feature', ',', 'which', 'is', \"n't\", 'much', 'of', 'a', 'complement', '.', 'Ginger', 'Lynn', 'was', 'at', 'least', 'notable', '(', 'if', 'you', 'ignore', 'the', 'shameful', \"'\", 'Oirish', 'accent', ')', ',', 'and', 'her', 'battle', 'with', 'the', 'hulking', 'killer', 'was', 'superbly', 'performed', 'and', 'choreographed', 'by', 'Alan', 'Chou', '.', 'Taylor', 'and', 'Jenna', 'delivered', 'expectedly', 'poor', 'dramatics', ',', 'which', 'could', 'have', 'been', 'caused', 'by', 'the', 'numerous', 'problems', 'on', '-', 'set', '.', 'Veil', \"'s\", 'direction', 'of', 'the', 'cinematography', 'was', 'excellently', 'constructed', 'and', 'he', 'provides', 'some', 'much', '-', 'needed', 'injections', 'of', 'suspense', '.', 'Exciting', 'and', 'crisp', 'photography', 'is', 'mixed', 'with', 'a', 'good', 'flair', 'for', 'storytelling', 'and', 'the', 'net', 'result', 'is', 'a', 'slasher', 'extravaganza', 'to', 'satisfy', 'even', 'the', 'most', 'critical', 'gore', 'hounds.<br', '/><br', '/>It', 'will', 'be', 'interesting', 'to', 'see', 'what', 'kind', 'of', 'final', 'cut', 'is', 'released', 'of', 'Samhain', '.', 'Rumor', 'has', 'it', 'that', 'a', 'second', 'director', 'was', 'drafted', 'in', 'to', 'shoot', 'a', 'different', 'ending', ',', 'and', 'I', \"'m\", 'curious', 'as', 'to', 'how', 'much', 'of', 'the', 'explicit', 'gore', 'will', 'remain', 'intact', 'for', 'worldwide', 'distribution', '.', 'If', 'the', 'end', 'result', 'is', 'only', 'half', 'as', 'good', 'as', 'the', 'rough', 'print', 'that', 'I', 'watched', ',', 'then', 'it', \"'s\", 'still', 'better', 'than', 'nearly', 'all', 'of', 'the', 'genre', 'pieces', 'that', 'have', 'been', 'unleashed', 'over', 'the', 'past', 'ten', 'years', '.', 'This', 'one', 'is', 'certainly', 'worth', 'checking', 'out', '\\x85'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JP-D7MhT6sbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ezk52iW-6ho4",
        "colab_type": "code",
        "outputId": "085799f9-01db-4d85-bdc9-fb6bfe06e6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EZzfor1y-Qam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=25000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBaGPJjR-VKq",
        "colab_type": "code",
        "outputId": "ce0cd2ba-c496-4681-970c-8f2dbd75e70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8g1RP87l-mFH",
        "colab_type": "code",
        "outputId": "e866ff44-262f-4e6d-8aa3-0f1ab67cbd33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 202828), (',', 192481), ('.', 165675), ('a', 109843), ('and', 109612), ('of', 100724), ('to', 93949), ('is', 76223), ('in', 61226), ('I', 54466), ('it', 54097), ('that', 49709), ('\"', 44112), (\"'s\", 43662), ('this', 42434), ('-', 36898), ('/><br', 35853), ('was', 35433), ('as', 30355), ('with', 29784)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cJqFjpYQ_aE-",
        "colab_type": "code",
        "outputId": "c60aaeb8-45bd-422e-f0d2-0890d2d63a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETILNzly_irD",
        "colab_type": "code",
        "outputId": "5d041771-fab7-45c8-962d-0e4a609b43ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7febadf88c80>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OdPZV4q6_oQG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8Ji25aPBAAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ]
    },
    {
      "metadata": {
        "id": "hvV4eJL2A_AR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mM4ZpCgBiKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WT_2pPOABn3N",
        "colab_type": "code",
        "outputId": "e0a5c66b-5b0b-4f49-98b0-2006abf7bfca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NksQbTc0BqcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ]
    },
    {
      "metadata": {
        "id": "M7JI0mZrB1vJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUp3mrcnB8j7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYGtFkuLDA0m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FR20TEwlDE_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16Y3mABFDMK9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkgG3KgRDQOM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "X-W47yhrDSXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jt1PonwRDcLF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A_6yvx-GDhIs",
        "colab_type": "code",
        "outputId": "fabcf4aa-a2b0-4e93-b6c8-eacdc7a6fd5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 7s\n",
            "\tTrain Loss: 0.694 | Train Acc: 50.11%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 49.69%\n",
            "Epoch: 02 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.62%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 49.59%\n",
            "Epoch: 03 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.98%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 50.73%\n",
            "Epoch: 04 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.70%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 49.56%\n",
            "Epoch: 05 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.95%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 50.64%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}